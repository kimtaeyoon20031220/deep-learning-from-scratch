{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from dataset.mnist import load_mnist"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4.1 곱셈 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulLayer:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        out = self.x * self.y\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * self.y\n",
    "        dy = dout * self.x\n",
    "\n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220.00000000000003\n"
     ]
    }
   ],
   "source": [
    "apple = 100\n",
    "apple_num = 2\n",
    "tax = 1.1\n",
    "\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
    "price = mul_tax_layer.forward(apple_price, tax)\n",
    "\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 200\n",
      "2.2 110.00000000000001\n"
     ]
    }
   ],
   "source": [
    "dprice = 1\n",
    "\n",
    "dapple_price, dtax = mul_tax_layer.backward(dprice)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "\n",
    "print(dapple_price, dtax)\n",
    "print(dapple, dapple_num)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4.2 덧셈 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        return x + y\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        return dout, dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 450 650 715.0000000000001\n"
     ]
    }
   ],
   "source": [
    "#그림 5-17 forward\n",
    "apple = 100\n",
    "orange = 150\n",
    "apple_num = 2\n",
    "orange_num = 3\n",
    "tax = 1.1\n",
    "\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_orange_layer = MulLayer()\n",
    "add_price_layer = AddLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "apple_all_price = mul_apple_layer.forward(apple, apple_num)\n",
    "orange_all_price = mul_orange_layer.forward(orange, orange_num)\n",
    "all_price = add_price_layer.forward(apple_all_price, orange_all_price)\n",
    "price_with_tax = mul_tax_layer.forward(all_price, tax)\n",
    "\n",
    "print(apple_all_price, orange_all_price, all_price, price_with_tax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.1 1.1 1.1 110.00000000000001 2.2 3.3000000000000003 165.0 650\n"
     ]
    }
   ],
   "source": [
    "#그림 5-17 backward\n",
    "\n",
    "dprice = 1\n",
    "dall_price, dtax = mul_tax_layer.backward(1)\n",
    "dapple_all_price, dorange_all_price = add_price_layer.backward(dall_price)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_all_price)\n",
    "dorange, dorange_num = mul_orange_layer.backward(dorange_all_price)\n",
    "\n",
    "print(dprice, dall_price, dapple_all_price, dorange_all_price, dapple_num, dapple, dorange, dorange_num, dtax)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 활성화 함수 계층 구현하기\n",
    "### 5.5.1 ReLU 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\n",
      "[13]\n"
     ]
    }
   ],
   "source": [
    "relu_layer = ReLU\n",
    "\n",
    "print(relu_layer.forward(relu_layer, np.array([5])))\n",
    "print(relu_layer.backward(relu_layer, np.array([13])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.2 Sigmoid 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = 1 / (1 + np.exp(-x))\n",
    "        self.out = out\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        return dout * self.out * (1 - self.out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9933071490757153\n",
      "0.006648056670790033\n"
     ]
    }
   ],
   "source": [
    "sigmoid_layer = Sigmoid\n",
    "\n",
    "print(sigmoid_layer.forward(sigmoid_layer, 5))\n",
    "print(sigmoid_layer.backward(sigmoid_layer, 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Affine/Softmax 계층 구현하기\n",
    "### 5.6.1 Affine 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,) (2, 3) (3,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X = np.random.rand(2) # (1, 2)\n",
    "W = np.random.rand(2, 3) # (2, 3)\n",
    "b = np.random.rand(3) # (1, 3)\n",
    "\n",
    "print(X.shape, W.shape, b.shape)\n",
    "\n",
    "y = np.dot(X, W) + b\n",
    "\n",
    "print(y.shape) # (1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0]\n",
      " [10 10 10]]\n",
      "[[ 1  2  3]\n",
      " [11 12 13]]\n"
     ]
    }
   ],
   "source": [
    "X_dot_W = np.array([[0, 0, 0], [10, 10, 10]])\n",
    "B = np.array([1, 2, 3])\n",
    "\n",
    "print(X_dot_W)\n",
    "print(X_dot_W + B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "[5 7 9]\n"
     ]
    }
   ],
   "source": [
    "dY = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(dY)\n",
    "dB = np.sum(dY, axis=0)\n",
    "print(dB)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2차원용 Affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.x = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        out = np.dot(x, self.W) + self.b\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.b = np.sum(dout, axis=0)\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6.3 Softmax-with-Loss 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from common.functions import softmax, cross_entropy_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(y, t)\n",
    "\n",
    "        return self.loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7.1 신경망 학습의 전체 그림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "from collections import OrderedDict\n",
    "\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std):\n",
    "        self.params = {}\n",
    "        self.params[\"W1\"] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params[\"b1\"] = np.zeros(hidden_size)\n",
    "        self.params[\"W2\"] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params[\"b2\"] = np.zeros(output_size)\n",
    "\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers[\"Affine1\"] = Affine(self.params[\"W1\"], self.params[\"b1\"])\n",
    "        self.layers[\"Relu1\"] = Relu()\n",
    "        self.layers[\"Affine2\"] = Affine(self.params[\"W2\"], self.params[\"b2\"])\n",
    "        self.lastLayer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.lastLayer.forward(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "\n",
    "        return accuracy\n",
    "    \n",
    "    def numerical_gradient(self, x, t):\n",
    "        grads = {}\n",
    "        grads[\"W1\"] = numerical_gradient(self.loss, self.params[\"W1\"])\n",
    "        grads[\"b1\"] = numerical_gradient(self.loss, self.params[\"b1\"])\n",
    "        grads[\"W2\"] = numerical_gradient(self.loss, self.params[\"W2\"])\n",
    "        grads[\"b2\"] = numerical_gradient(self.loss, self.params[\"b2\"])\n",
    "\n",
    "        return grads\n",
    "    \n",
    "    def gradient(self, x, t):\n",
    "        #순전파\n",
    "        self.loss(x, t)\n",
    "        \n",
    "        #역전파\n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 이해 안되면 common/layers/의 Affine 클래스 참조하세요.\n",
    "        grads = {}\n",
    "        grads[\"W1\"] = self.layers[\"Affine1\"].dW \n",
    "        grads[\"b1\"] = self.layers[\"Affine1\"].db\n",
    "        grads[\"W2\"] = self.layers[\"Affine2\"].dW\n",
    "        grads[\"b2\"] = self.layers[\"Affine2\"].db\n",
    "\n",
    "        return grads"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7.3 오차역전파법으로 구한 기울기 검증하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: 9.821061997929637e-07\n",
      "key: 1.0904181849873482e-05\n",
      "key: 7.288939145928493e-09\n",
      "key: 1.4082794891900896e-07\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "x_batch = x_train[:3]\n",
    "t_batch = t_train[:3]\n",
    "\n",
    "grad_numerical = network.numerical_gradient(x_batch, t_batch)\n",
    "grad_backprop = network.gradient(x_batch, t_batch)\n",
    "\n",
    "for key in grad_numerical.keys():\n",
    "    diff = np.average(np.abs(grad_backprop[key] - grad_numerical[key]))\n",
    "    print(f\"key: {diff}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7.4 오차역전파법을 사용한 학습 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08951666666666666 0.0898\n",
      "0.1162 0.1203\n",
      "0.1031 0.1019\n",
      "0.12931666666666666 0.134\n",
      "0.10838333333333333 0.1103\n",
      "0.11718333333333333 0.1179\n",
      "0.124 0.1229\n",
      "0.15613333333333335 0.1568\n",
      "0.16523333333333334 0.1703\n",
      "0.16351666666666667 0.1683\n",
      "0.17545 0.1787\n",
      "0.2049 0.2041\n",
      "0.18431666666666666 0.1844\n",
      "0.1814 0.1801\n",
      "0.17586666666666667 0.1744\n",
      "0.18021666666666666 0.1828\n",
      "0.20301666666666668 0.2028\n",
      "0.21466666666666667 0.2135\n",
      "0.19306666666666666 0.1936\n",
      "0.2586833333333333 0.2594\n",
      "0.138 0.1373\n",
      "0.17915 0.1765\n",
      "0.19825 0.1957\n",
      "0.28981666666666667 0.2938\n",
      "0.2547 0.2566\n",
      "0.25046666666666667 0.2514\n",
      "0.30846666666666667 0.3112\n",
      "0.34625 0.3504\n",
      "0.33575 0.3404\n",
      "0.3616666666666667 0.3652\n",
      "0.37783333333333335 0.3832\n",
      "0.4044833333333333 0.4134\n",
      "0.43366666666666664 0.446\n",
      "0.4129333333333333 0.42\n",
      "0.3571166666666667 0.3618\n",
      "0.3430666666666667 0.3467\n",
      "0.3494 0.3534\n",
      "0.3687 0.376\n",
      "0.34021666666666667 0.3481\n",
      "0.34355 0.3486\n",
      "0.3683166666666667 0.3729\n",
      "0.3260166666666667 0.3327\n",
      "0.34518333333333334 0.3517\n",
      "0.40348333333333336 0.4111\n",
      "0.41695 0.4279\n",
      "0.4269 0.4369\n",
      "0.39175 0.4057\n",
      "0.3678 0.3811\n",
      "0.33366666666666667 0.3428\n",
      "0.34026666666666666 0.3505\n",
      "0.35678333333333334 0.3648\n",
      "0.39823333333333333 0.4135\n",
      "0.3918333333333333 0.4021\n",
      "0.4229 0.437\n",
      "0.43611666666666665 0.4574\n",
      "0.46441666666666664 0.482\n",
      "0.47951666666666665 0.4919\n",
      "0.49933333333333335 0.5134\n",
      "0.46586666666666665 0.4795\n",
      "0.4812166666666667 0.4944\n",
      "0.3667666666666667 0.3806\n",
      "0.36578333333333335 0.3755\n",
      "0.4021166666666667 0.4114\n",
      "0.41725 0.4271\n",
      "0.49346666666666666 0.5148\n",
      "0.5162833333333333 0.5358\n",
      "0.5269166666666667 0.5456\n",
      "0.47331666666666666 0.487\n",
      "0.5183 0.5337\n",
      "0.48815 0.4978\n",
      "0.5288 0.542\n",
      "0.51235 0.5182\n",
      "0.53115 0.5363\n",
      "0.5129666666666667 0.5137\n",
      "0.52835 0.5316\n",
      "0.52255 0.5258\n",
      "0.5353 0.5387\n",
      "0.57855 0.5924\n",
      "0.55535 0.5638\n",
      "0.5413333333333333 0.5452\n",
      "0.5399666666666667 0.5444\n",
      "0.5352333333333333 0.5372\n",
      "0.5339833333333334 0.5354\n",
      "0.5375333333333333 0.5414\n",
      "0.5197 0.5214\n",
      "0.5463833333333333 0.5494\n",
      "0.5537 0.5546\n",
      "0.5781333333333334 0.5782\n",
      "0.6079666666666667 0.6079\n",
      "0.6205333333333334 0.6214\n",
      "0.5904333333333334 0.5927\n",
      "0.6267166666666667 0.632\n",
      "0.64775 0.6525\n",
      "0.6662666666666667 0.6726\n",
      "0.7033166666666667 0.7162\n",
      "0.6762 0.6878\n",
      "0.698 0.706\n",
      "0.6591333333333333 0.6721\n",
      "0.6173833333333333 0.6232\n",
      "0.6641333333333334 0.6747\n",
      "0.7295 0.7447\n",
      "0.7094833333333334 0.7203\n",
      "0.736 0.7432\n",
      "0.7096166666666667 0.7161\n",
      "0.7202833333333334 0.7271\n",
      "0.7298 0.7354\n",
      "0.7366333333333334 0.7475\n",
      "0.7178666666666667 0.7241\n",
      "0.7332166666666666 0.7413\n",
      "0.7409 0.7494\n",
      "0.7486333333333334 0.7582\n",
      "0.7212833333333334 0.7321\n",
      "0.7528666666666667 0.7622\n",
      "0.7651 0.772\n",
      "0.7325 0.7354\n",
      "0.7399166666666667 0.7454\n",
      "0.7785833333333333 0.7866\n",
      "0.7812333333333333 0.7873\n",
      "0.76385 0.7745\n",
      "0.7469333333333333 0.7515\n",
      "0.7416833333333334 0.7513\n",
      "0.7393166666666666 0.7505\n",
      "0.7451666666666666 0.7552\n",
      "0.76185 0.7732\n",
      "0.7748166666666667 0.7841\n",
      "0.7569666666666667 0.7645\n",
      "0.7600333333333333 0.7646\n",
      "0.7546166666666667 0.7616\n",
      "0.7687 0.7745\n",
      "0.7914333333333333 0.7988\n",
      "0.79215 0.798\n",
      "0.7839833333333334 0.791\n",
      "0.8000833333333334 0.8049\n",
      "0.7906833333333333 0.7977\n",
      "0.7762 0.7845\n",
      "0.77565 0.7848\n",
      "0.7853666666666667 0.7901\n",
      "0.7841333333333333 0.7936\n",
      "0.7996166666666666 0.8038\n",
      "0.8032666666666667 0.8065\n",
      "0.7890333333333334 0.7983\n",
      "0.8008333333333333 0.8035\n",
      "0.8045666666666667 0.8122\n",
      "0.80645 0.8134\n",
      "0.8046833333333333 0.8098\n",
      "0.7836333333333333 0.794\n",
      "0.79755 0.8052\n",
      "0.8088 0.8157\n",
      "0.8120666666666667 0.817\n",
      "0.7989166666666667 0.8082\n",
      "0.8026166666666666 0.8101\n",
      "0.8149333333333333 0.8174\n",
      "0.8047333333333333 0.8103\n",
      "0.8178166666666666 0.8254\n",
      "0.8199166666666666 0.826\n",
      "0.80555 0.8148\n",
      "0.8134666666666667 0.821\n",
      "0.80035 0.809\n",
      "0.7901833333333333 0.7986\n",
      "0.80415 0.8125\n",
      "0.81275 0.8184\n",
      "0.8202 0.8275\n",
      "0.8215833333333333 0.8293\n",
      "0.8222666666666667 0.8285\n",
      "0.81545 0.8207\n",
      "0.82295 0.8276\n",
      "0.8166833333333333 0.8222\n",
      "0.7984 0.8049\n",
      "0.8144666666666667 0.8205\n",
      "0.8299666666666666 0.8339\n",
      "0.8278166666666666 0.8313\n",
      "0.8260333333333333 0.8332\n",
      "0.8371166666666666 0.841\n",
      "0.8266833333333333 0.8324\n",
      "0.82655 0.8318\n",
      "0.8343333333333334 0.8387\n",
      "0.8345 0.8398\n",
      "0.8306333333333333 0.8379\n",
      "0.8383666666666667 0.8436\n",
      "0.8279833333333333 0.8374\n",
      "0.8246833333333333 0.8326\n",
      "0.8339166666666666 0.8408\n",
      "0.8359 0.8407\n",
      "0.8411833333333333 0.8482\n",
      "0.8401666666666666 0.8451\n",
      "0.8363666666666667 0.8399\n",
      "0.8350166666666666 0.8411\n",
      "0.8339333333333333 0.8383\n",
      "0.8287333333333333 0.8344\n",
      "0.83895 0.8448\n",
      "0.8327166666666667 0.8386\n",
      "0.8462333333333333 0.8504\n",
      "0.8426 0.8493\n",
      "0.8380666666666666 0.8438\n",
      "0.8451166666666666 0.8503\n",
      "0.83465 0.8434\n",
      "0.8380166666666666 0.8436\n",
      "0.8426666666666667 0.8478\n",
      "0.8448833333333333 0.8491\n",
      "0.8455666666666667 0.8499\n",
      "0.8414333333333334 0.8442\n",
      "0.8448333333333333 0.847\n",
      "0.8473166666666667 0.8517\n",
      "0.8460333333333333 0.8516\n",
      "0.8478833333333333 0.8514\n",
      "0.8540833333333333 0.8588\n",
      "0.8497333333333333 0.8554\n",
      "0.8454 0.8538\n",
      "0.8472166666666666 0.8546\n",
      "0.8528666666666667 0.8578\n",
      "0.8513 0.8557\n",
      "0.8440666666666666 0.8499\n",
      "0.8456166666666667 0.8465\n",
      "0.85495 0.8578\n",
      "0.84725 0.8533\n",
      "0.8534166666666667 0.8579\n",
      "0.8504166666666667 0.8536\n",
      "0.8551 0.8574\n",
      "0.8514166666666667 0.8516\n",
      "0.86035 0.8628\n",
      "0.8600333333333333 0.8637\n",
      "0.8601166666666666 0.8632\n",
      "0.85775 0.8606\n",
      "0.8574333333333334 0.8592\n",
      "0.8580166666666666 0.8616\n",
      "0.8511833333333333 0.8567\n",
      "0.8529833333333333 0.8606\n",
      "0.86055 0.867\n",
      "0.8624166666666667 0.8681\n",
      "0.8633166666666666 0.8689\n",
      "0.8644666666666667 0.8674\n",
      "0.8642166666666666 0.869\n",
      "0.8625833333333334 0.8675\n",
      "0.8616166666666667 0.8654\n",
      "0.8619166666666667 0.8677\n",
      "0.8609833333333333 0.8631\n",
      "0.8610333333333333 0.8634\n",
      "0.8621333333333333 0.864\n",
      "0.8586166666666667 0.8615\n",
      "0.8492333333333333 0.8524\n",
      "0.86235 0.8652\n",
      "0.8595 0.8603\n",
      "0.8618666666666667 0.8653\n",
      "0.8603666666666666 0.8658\n",
      "0.86395 0.8666\n",
      "0.8698166666666667 0.8732\n",
      "0.8655166666666667 0.8678\n",
      "0.8628833333333333 0.8672\n",
      "0.8635833333333334 0.8649\n",
      "0.8587166666666667 0.8605\n",
      "0.8669166666666667 0.8716\n",
      "0.8590333333333333 0.8636\n",
      "0.8659333333333333 0.8711\n",
      "0.8674 0.8725\n",
      "0.86885 0.874\n",
      "0.8705666666666667 0.8754\n",
      "0.8669 0.8747\n",
      "0.8698833333333333 0.8737\n",
      "0.87085 0.8734\n",
      "0.8652166666666666 0.8684\n",
      "0.86745 0.8719\n",
      "0.8675833333333334 0.8705\n",
      "0.8643833333333333 0.8681\n",
      "0.8667 0.8696\n",
      "0.8716666666666667 0.8743\n",
      "0.8677 0.8735\n",
      "0.8725166666666667 0.8765\n",
      "0.86945 0.8748\n",
      "0.8667666666666667 0.869\n",
      "0.8741333333333333 0.8786\n",
      "0.8731 0.8776\n",
      "0.8743833333333333 0.8793\n",
      "0.8726833333333334 0.8776\n",
      "0.8667333333333334 0.8733\n",
      "0.8731333333333333 0.8788\n",
      "0.8708166666666667 0.8743\n",
      "0.8721 0.8747\n",
      "0.8706166666666667 0.8752\n",
      "0.8607833333333333 0.8619\n",
      "0.8687 0.8733\n",
      "0.8779666666666667 0.8821\n",
      "0.8735 0.8774\n",
      "0.8722833333333333 0.8773\n",
      "0.8692833333333333 0.8758\n",
      "0.8764166666666666 0.8793\n",
      "0.8679833333333333 0.8714\n",
      "0.8757333333333334 0.88\n",
      "0.8768666666666667 0.8812\n",
      "0.8726 0.8794\n",
      "0.8724 0.8779\n",
      "0.8786833333333334 0.884\n",
      "0.8763333333333333 0.8801\n",
      "0.8736666666666667 0.8765\n",
      "0.8669166666666667 0.8679\n",
      "0.8758333333333334 0.8801\n",
      "0.8778666666666667 0.8781\n",
      "0.8787166666666667 0.8801\n",
      "0.8787 0.8825\n",
      "0.8773166666666666 0.8793\n",
      "0.8773833333333333 0.8808\n",
      "0.8788666666666667 0.885\n",
      "0.8810333333333333 0.8844\n",
      "0.8786666666666667 0.8833\n",
      "0.8755833333333334 0.8825\n",
      "0.88035 0.8843\n",
      "0.8778 0.8838\n",
      "0.8765833333333334 0.8829\n",
      "0.88065 0.8872\n",
      "0.8809666666666667 0.8864\n",
      "0.8808333333333334 0.8844\n",
      "0.8763666666666666 0.8818\n",
      "0.8714166666666666 0.8771\n",
      "0.8797666666666667 0.8844\n",
      "0.8763333333333333 0.8819\n",
      "0.8822666666666666 0.8868\n",
      "0.8796333333333334 0.8844\n",
      "0.8803666666666666 0.8862\n",
      "0.8770666666666667 0.8844\n",
      "0.88095 0.8884\n",
      "0.8803 0.8846\n",
      "0.8728333333333333 0.8758\n",
      "0.8807 0.884\n",
      "0.8828666666666667 0.8862\n",
      "0.8849166666666667 0.8893\n",
      "0.8784166666666666 0.8843\n",
      "0.8820166666666667 0.8883\n",
      "0.8852666666666666 0.8909\n",
      "0.8775166666666666 0.8826\n",
      "0.88395 0.888\n",
      "0.8852666666666666 0.8897\n",
      "0.8845833333333334 0.8891\n",
      "0.8849 0.8889\n",
      "0.8829 0.8874\n",
      "0.8851 0.8882\n",
      "0.8855166666666666 0.8884\n",
      "0.8826333333333334 0.8866\n",
      "0.8835166666666666 0.8877\n",
      "0.8815666666666667 0.8875\n",
      "0.8848333333333334 0.8907\n",
      "0.8812166666666666 0.8823\n",
      "0.87895 0.8877\n",
      "0.8790166666666667 0.888\n",
      "0.8804 0.8887\n",
      "0.8820333333333333 0.888\n",
      "0.8827833333333334 0.888\n",
      "0.8866666666666667 0.8909\n",
      "0.8868333333333334 0.8893\n",
      "0.8849833333333333 0.8863\n",
      "0.8853333333333333 0.8878\n",
      "0.88455 0.8881\n",
      "0.8800833333333333 0.8823\n",
      "0.8836166666666667 0.8878\n",
      "0.8809166666666667 0.8863\n",
      "0.8825166666666666 0.8865\n",
      "0.8812 0.8868\n",
      "0.88485 0.8899\n",
      "0.8783 0.8842\n",
      "0.88775 0.8919\n",
      "0.8856333333333334 0.8893\n",
      "0.8869166666666667 0.8904\n",
      "0.8881333333333333 0.8907\n",
      "0.8889166666666667 0.8924\n",
      "0.8881 0.8916\n",
      "0.8882833333333333 0.8919\n",
      "0.88965 0.8914\n",
      "0.88625 0.8909\n",
      "0.88635 0.8915\n",
      "0.8883833333333333 0.8933\n",
      "0.8901666666666667 0.8926\n",
      "0.8881 0.8916\n",
      "0.8826 0.8858\n",
      "0.8853333333333333 0.8888\n",
      "0.8822 0.883\n",
      "0.8872833333333333 0.8894\n",
      "0.8867833333333334 0.8914\n",
      "0.8872666666666666 0.8924\n",
      "0.8879833333333333 0.893\n",
      "0.8879333333333334 0.8925\n",
      "0.8876833333333334 0.8914\n",
      "0.8889666666666667 0.8918\n",
      "0.8893666666666666 0.8952\n",
      "0.8869166666666667 0.8932\n",
      "0.8878166666666667 0.8904\n",
      "0.8885166666666666 0.8944\n",
      "0.8875833333333333 0.8916\n",
      "0.8891333333333333 0.8942\n",
      "0.8907833333333334 0.8955\n",
      "0.8907333333333334 0.8955\n",
      "0.8889 0.8944\n",
      "0.8899666666666667 0.896\n",
      "0.89085 0.8953\n",
      "0.8906333333333334 0.8967\n",
      "0.89135 0.8961\n",
      "0.8900166666666667 0.8932\n",
      "0.8911166666666667 0.8943\n",
      "0.8873833333333333 0.8908\n",
      "0.8916333333333334 0.8978\n",
      "0.8918 0.8965\n",
      "0.8895666666666666 0.8941\n",
      "0.8911333333333333 0.8969\n",
      "0.89095 0.8936\n",
      "0.8906 0.895\n",
      "0.8886333333333334 0.8924\n",
      "0.8913833333333333 0.8951\n",
      "0.88835 0.8914\n",
      "0.8865 0.8906\n",
      "0.8882333333333333 0.8963\n",
      "0.8901666666666667 0.8963\n",
      "0.8900666666666667 0.8967\n",
      "0.88985 0.8962\n",
      "0.8924833333333333 0.8973\n",
      "0.8920666666666667 0.8939\n",
      "0.8922833333333333 0.8937\n",
      "0.8927 0.8948\n",
      "0.8937 0.8958\n",
      "0.8942 0.8977\n",
      "0.8941333333333333 0.8981\n",
      "0.89385 0.8979\n",
      "0.8930833333333333 0.8975\n",
      "0.8893833333333333 0.8971\n",
      "0.8924666666666666 0.8942\n",
      "0.8916833333333334 0.8916\n",
      "0.89295 0.8962\n",
      "0.8932 0.8973\n",
      "0.8935 0.899\n",
      "0.89495 0.8987\n",
      "0.8944166666666666 0.9\n",
      "0.8935 0.8987\n",
      "0.8943666666666666 0.8966\n",
      "0.8941833333333333 0.8987\n",
      "0.8927 0.8986\n",
      "0.89175 0.8964\n",
      "0.8911833333333333 0.8952\n",
      "0.89275 0.8973\n",
      "0.8928666666666667 0.8991\n",
      "0.8927 0.8974\n",
      "0.8948166666666667 0.8968\n",
      "0.8944833333333333 0.8954\n",
      "0.892 0.8954\n",
      "0.8942833333333333 0.8977\n",
      "0.8932 0.8977\n",
      "0.8945833333333333 0.8987\n",
      "0.8939 0.899\n",
      "0.8947833333333334 0.9001\n",
      "0.89575 0.8995\n",
      "0.8953166666666666 0.8983\n",
      "0.8908 0.8947\n",
      "0.8953333333333333 0.9005\n",
      "0.89495 0.8984\n",
      "0.8976333333333333 0.899\n",
      "0.8920333333333333 0.8966\n",
      "0.8956166666666666 0.8981\n",
      "0.8936833333333334 0.8946\n",
      "0.89555 0.8979\n",
      "0.88985 0.8908\n",
      "0.8901833333333333 0.8928\n",
      "0.8897 0.8914\n",
      "0.8914333333333333 0.8948\n",
      "0.8951833333333333 0.8991\n",
      "0.8942 0.8975\n",
      "0.8903666666666666 0.8937\n",
      "0.8947166666666667 0.8969\n",
      "0.8924666666666666 0.8986\n",
      "0.8965 0.9007\n",
      "0.8975666666666666 0.9015\n",
      "0.8959833333333334 0.8987\n",
      "0.89805 0.9008\n",
      "0.8977166666666667 0.8989\n",
      "0.8976166666666666 0.899\n",
      "0.8968333333333334 0.9007\n",
      "0.8981333333333333 0.9016\n",
      "0.8975833333333333 0.9007\n",
      "0.8953333333333333 0.8986\n",
      "0.8977333333333334 0.9015\n",
      "0.89065 0.896\n",
      "0.89435 0.899\n",
      "0.8980666666666667 0.9018\n",
      "0.8943333333333333 0.8993\n",
      "0.8963833333333333 0.8998\n",
      "0.8915166666666666 0.896\n",
      "0.8959333333333334 0.8988\n",
      "0.89535 0.8979\n",
      "0.8981333333333333 0.9035\n",
      "0.8981666666666667 0.9009\n",
      "0.8969166666666667 0.9012\n",
      "0.8919833333333334 0.893\n",
      "0.8912166666666667 0.8921\n",
      "0.8963666666666666 0.8993\n",
      "0.89745 0.9011\n",
      "0.8955166666666666 0.8998\n",
      "0.8936666666666667 0.8998\n",
      "0.89495 0.9013\n",
      "0.8981333333333333 0.9031\n",
      "0.8992666666666667 0.9044\n",
      "0.9002666666666667 0.9026\n",
      "0.8979166666666667 0.9039\n",
      "0.89815 0.9041\n",
      "0.9000333333333334 0.9032\n",
      "0.8992333333333333 0.9036\n",
      "0.8996 0.9021\n",
      "0.8976666666666666 0.8987\n",
      "0.8982333333333333 0.9013\n",
      "0.8957833333333334 0.9002\n",
      "0.8972166666666667 0.9019\n",
      "0.896 0.9021\n",
      "0.8984333333333333 0.902\n",
      "0.9003833333333333 0.9042\n",
      "0.9003166666666667 0.9024\n",
      "0.8995666666666666 0.9038\n",
      "0.89865 0.9041\n",
      "0.8987333333333334 0.9026\n",
      "0.8966666666666666 0.9013\n",
      "0.8947833333333334 0.8986\n",
      "0.8972 0.9036\n",
      "0.89895 0.9013\n",
      "0.9006833333333333 0.9025\n",
      "0.8995666666666666 0.9021\n",
      "0.8995666666666666 0.8987\n",
      "0.8995 0.9017\n",
      "0.8988666666666667 0.901\n",
      "0.8943833333333333 0.899\n",
      "0.8989666666666667 0.9\n",
      "0.8981833333333333 0.9015\n",
      "0.8982666666666667 0.9013\n",
      "0.9017833333333334 0.9029\n",
      "0.8986666666666666 0.9025\n",
      "0.8972166666666667 0.8989\n",
      "0.8954 0.8966\n",
      "0.89985 0.9006\n",
      "0.8989166666666667 0.8994\n",
      "0.8970666666666667 0.8983\n",
      "0.9003833333333333 0.9031\n",
      "0.89955 0.9026\n",
      "0.8982 0.9018\n",
      "0.8975666666666666 0.9014\n",
      "0.89935 0.9036\n",
      "0.8996 0.9023\n",
      "0.9010166666666667 0.9034\n",
      "0.9005333333333333 0.9049\n",
      "0.9013 0.9061\n",
      "0.90215 0.905\n",
      "0.9021833333333333 0.9028\n",
      "0.9018166666666667 0.9053\n",
      "0.9002833333333333 0.9024\n",
      "0.8967 0.8996\n",
      "0.89595 0.9001\n",
      "0.89745 0.9026\n",
      "0.9015833333333333 0.9041\n",
      "0.9010333333333334 0.9042\n",
      "0.89835 0.901\n",
      "0.9007833333333334 0.9047\n",
      "0.9005833333333333 0.9039\n",
      "0.9005166666666666 0.9007\n",
      "0.90015 0.9046\n",
      "0.9011166666666667 0.9043\n",
      "0.9026 0.9055\n",
      "0.9008 0.904\n",
      "0.89955 0.902\n",
      "0.9007 0.9044\n",
      "0.8981333333333333 0.9034\n",
      "0.9005666666666666 0.9042\n",
      "0.9014833333333333 0.9083\n",
      "0.9019833333333334 0.9073\n",
      "0.9018833333333334 0.9065\n",
      "0.9024833333333333 0.9044\n",
      "0.9039666666666667 0.9064\n",
      "0.9023 0.9076\n",
      "0.9028166666666667 0.9055\n",
      "0.9029 0.9061\n",
      "0.90375 0.9055\n",
      "0.9036 0.9074\n",
      "0.9017666666666667 0.9073\n",
      "0.9032666666666667 0.905\n",
      "0.90135 0.903\n",
      "0.9012833333333333 0.9026\n",
      "0.9006 0.9036\n",
      "0.8993 0.9024\n",
      "0.9011166666666667 0.9032\n",
      "0.9004166666666666 0.9031\n",
      "0.9000833333333333 0.9007\n",
      "0.9017666666666667 0.9021\n",
      "0.9003666666666666 0.9001\n",
      "0.8990166666666667 0.8999\n",
      "0.90115 0.9012\n",
      "0.9019 0.9068\n",
      "0.9033666666666667 0.9075\n",
      "0.9029833333333334 0.9089\n",
      "0.90315 0.9077\n",
      "0.9016666666666666 0.9044\n",
      "0.9010666666666667 0.9068\n",
      "0.89945 0.9039\n",
      "0.90375 0.9078\n",
      "0.90185 0.9041\n",
      "0.9028 0.9046\n",
      "0.9030666666666667 0.9038\n",
      "0.9034333333333333 0.9043\n",
      "0.9049833333333334 0.9068\n",
      "0.90515 0.9076\n",
      "0.9051333333333333 0.9085\n",
      "0.9043833333333333 0.9074\n",
      "0.90415 0.9046\n",
      "0.9014166666666666 0.905\n",
      "0.9023833333333333 0.9062\n",
      "0.9047833333333334 0.9074\n",
      "0.8958666666666667 0.9005\n",
      "0.9004666666666666 0.9051\n",
      "0.9005666666666666 0.905\n",
      "0.9032833333333333 0.9068\n",
      "0.9010666666666667 0.9056\n",
      "0.9024833333333333 0.9077\n",
      "0.9053833333333333 0.9069\n",
      "0.9038666666666667 0.9049\n",
      "0.9041166666666667 0.9065\n",
      "0.9002666666666667 0.9055\n",
      "0.9035333333333333 0.9072\n",
      "0.9040333333333334 0.9059\n",
      "0.9050166666666667 0.9063\n",
      "0.9039833333333334 0.9048\n",
      "0.90525 0.9065\n",
      "0.9054833333333333 0.9079\n",
      "0.9023333333333333 0.9049\n",
      "0.90425 0.9057\n",
      "0.9026166666666666 0.906\n",
      "0.9035166666666666 0.9063\n",
      "0.9048833333333334 0.9071\n",
      "0.9049833333333334 0.9075\n",
      "0.9044 0.9075\n",
      "0.9037666666666667 0.907\n",
      "0.90395 0.9089\n",
      "0.9023833333333333 0.9063\n",
      "0.8984666666666666 0.904\n",
      "0.89985 0.9025\n",
      "0.9035 0.9059\n",
      "0.9037333333333334 0.9054\n",
      "0.9051 0.9083\n",
      "0.9052666666666667 0.9064\n",
      "0.9054666666666666 0.907\n",
      "0.90565 0.9083\n",
      "0.905 0.9065\n",
      "0.905 0.9075\n",
      "0.9053166666666667 0.9061\n",
      "0.9052333333333333 0.9069\n",
      "0.9057 0.9067\n",
      "0.8979 0.9008\n",
      "0.9023 0.9044\n",
      "0.90225 0.9045\n",
      "0.9052833333333333 0.9057\n",
      "0.9049833333333334 0.9056\n",
      "0.9061833333333333 0.9092\n",
      "0.9063666666666667 0.9081\n",
      "0.90755 0.908\n",
      "0.9079666666666667 0.9067\n",
      "0.9057 0.9091\n",
      "0.9039833333333334 0.9073\n",
      "0.9064166666666666 0.9071\n",
      "0.9057833333333334 0.9065\n",
      "0.90645 0.9093\n",
      "0.9061 0.9076\n",
      "0.904 0.9079\n",
      "0.90215 0.9037\n",
      "0.9038666666666667 0.9053\n",
      "0.9064833333333333 0.9099\n",
      "0.9054 0.9053\n",
      "0.9069166666666667 0.9072\n",
      "0.9082666666666667 0.9094\n",
      "0.9080666666666667 0.9109\n",
      "0.9065166666666666 0.9089\n",
      "0.90405 0.9082\n",
      "0.9079833333333334 0.9105\n",
      "0.9083166666666667 0.9103\n",
      "0.9073333333333333 0.9095\n",
      "0.9043666666666667 0.908\n",
      "0.9048333333333334 0.9096\n",
      "0.9063333333333333 0.9094\n",
      "0.9046666666666666 0.9085\n",
      "0.906 0.9092\n",
      "0.9069 0.9099\n",
      "0.9076666666666666 0.9102\n",
      "0.9060166666666667 0.9083\n",
      "0.9085 0.9099\n",
      "0.9068166666666667 0.908\n",
      "0.9046333333333333 0.9058\n",
      "0.9058 0.9076\n",
      "0.9042833333333333 0.9065\n",
      "0.9058666666666667 0.9061\n",
      "0.9079333333333334 0.9103\n",
      "0.9081666666666667 0.9114\n",
      "0.9069333333333334 0.9129\n",
      "0.90715 0.9108\n",
      "0.9078833333333334 0.9119\n",
      "0.9074833333333333 0.9119\n",
      "0.9079833333333334 0.9107\n",
      "0.90745 0.9083\n",
      "0.90345 0.9047\n",
      "0.90805 0.9095\n",
      "0.9056 0.9101\n",
      "0.9069666666666667 0.9107\n",
      "0.90705 0.9099\n",
      "0.9064666666666666 0.9088\n",
      "0.9087833333333334 0.9106\n",
      "0.9061 0.9115\n",
      "0.90785 0.9121\n",
      "0.9091833333333333 0.9118\n",
      "0.9096 0.9117\n",
      "0.9092333333333333 0.9101\n",
      "0.90595 0.9078\n",
      "0.9071333333333333 0.91\n",
      "0.9086 0.9106\n",
      "0.9076166666666666 0.9098\n",
      "0.9074 0.9096\n",
      "0.9046666666666666 0.9084\n",
      "0.9076166666666666 0.9129\n",
      "0.9068333333333334 0.912\n",
      "0.9030666666666667 0.9087\n",
      "0.90565 0.9097\n",
      "0.9071166666666667 0.9104\n",
      "0.9081666666666667 0.9119\n",
      "0.9078 0.9108\n",
      "0.9075 0.9094\n",
      "0.9084333333333333 0.9097\n",
      "0.9088 0.9108\n",
      "0.9086833333333333 0.9115\n",
      "0.9062333333333333 0.9101\n",
      "0.9064 0.9088\n",
      "0.9078833333333334 0.9115\n",
      "0.9060833333333334 0.912\n",
      "0.908 0.9116\n",
      "0.9102833333333333 0.9119\n",
      "0.9094833333333333 0.9131\n",
      "0.9093 0.9123\n",
      "0.90895 0.9105\n",
      "0.9078 0.9098\n",
      "0.9084833333333333 0.908\n",
      "0.9080333333333334 0.9098\n",
      "0.9095333333333333 0.9096\n",
      "0.9091166666666667 0.9114\n",
      "0.90825 0.9114\n",
      "0.9051166666666667 0.9081\n",
      "0.9064 0.9112\n",
      "0.9057666666666667 0.91\n",
      "0.9081 0.9123\n",
      "0.9054166666666666 0.9096\n",
      "0.9101833333333333 0.9121\n",
      "0.9065833333333333 0.911\n",
      "0.9083666666666667 0.9117\n",
      "0.9084666666666666 0.9118\n",
      "0.9098333333333334 0.9135\n",
      "0.9098833333333334 0.9137\n",
      "0.9047 0.9092\n",
      "0.9053166666666667 0.9104\n",
      "0.90855 0.9099\n",
      "0.9085333333333333 0.911\n",
      "0.9073666666666667 0.9094\n",
      "0.9099166666666667 0.9102\n",
      "0.9068 0.9103\n",
      "0.9098166666666667 0.9121\n",
      "0.9111166666666667 0.9123\n",
      "0.9085833333333333 0.9116\n",
      "0.9096333333333333 0.9119\n",
      "0.90975 0.9122\n",
      "0.9096333333333333 0.913\n",
      "0.9101666666666667 0.9142\n",
      "0.9093 0.9133\n",
      "0.9114 0.916\n",
      "0.9107166666666666 0.9143\n",
      "0.9114 0.9147\n",
      "0.9097666666666666 0.9138\n",
      "0.9100333333333334 0.9145\n",
      "0.90875 0.9133\n",
      "0.9108833333333334 0.913\n",
      "0.9107166666666666 0.9139\n",
      "0.9083 0.9096\n",
      "0.9098666666666667 0.9109\n",
      "0.90975 0.9125\n",
      "0.9108666666666667 0.9135\n",
      "0.90885 0.9127\n",
      "0.9100166666666667 0.914\n",
      "0.91075 0.9135\n",
      "0.9089333333333334 0.9142\n",
      "0.9106666666666666 0.9138\n",
      "0.9101666666666667 0.9144\n",
      "0.91015 0.9137\n",
      "0.9086833333333333 0.9116\n",
      "0.9069666666666667 0.9123\n",
      "0.9073833333333333 0.9124\n",
      "0.9071333333333333 0.9125\n",
      "0.90635 0.9115\n",
      "0.90745 0.9116\n",
      "0.9088666666666667 0.9136\n",
      "0.91035 0.9161\n",
      "0.90975 0.9159\n",
      "0.9101 0.9158\n",
      "0.9094333333333333 0.9147\n",
      "0.9092166666666667 0.9134\n",
      "0.9076666666666666 0.9113\n",
      "0.9114 0.9151\n",
      "0.9110666666666667 0.9135\n",
      "0.9117333333333333 0.9154\n",
      "0.91215 0.9153\n",
      "0.9108833333333334 0.9158\n",
      "0.9121 0.915\n",
      "0.9115 0.9163\n",
      "0.9107 0.9141\n",
      "0.9090833333333334 0.9134\n",
      "0.90855 0.9138\n",
      "0.91175 0.9164\n",
      "0.9114833333333333 0.9166\n",
      "0.91225 0.9164\n",
      "0.9120333333333334 0.9158\n",
      "0.9098833333333334 0.9138\n",
      "0.9099166666666667 0.9133\n",
      "0.9099666666666667 0.9124\n",
      "0.9092333333333333 0.9115\n",
      "0.90845 0.9098\n",
      "0.9109333333333334 0.9126\n",
      "0.9122666666666667 0.9177\n",
      "0.9115 0.9176\n",
      "0.9129 0.9181\n",
      "0.9117666666666666 0.9184\n",
      "0.9136333333333333 0.9195\n",
      "0.91395 0.9206\n",
      "0.9128666666666667 0.9194\n",
      "0.91315 0.9186\n",
      "0.9131166666666667 0.9165\n",
      "0.9015 0.9054\n",
      "0.90785 0.9138\n",
      "0.91185 0.9171\n",
      "0.91255 0.9166\n",
      "0.9105 0.9144\n",
      "0.91185 0.9166\n",
      "0.9111833333333333 0.917\n",
      "0.9133833333333333 0.9188\n",
      "0.9127833333333333 0.9185\n",
      "0.9143 0.9184\n",
      "0.9132833333333333 0.9176\n",
      "0.9125666666666666 0.9165\n",
      "0.9134333333333333 0.9191\n",
      "0.91185 0.9192\n",
      "0.9133 0.9181\n",
      "0.9122333333333333 0.9159\n",
      "0.9123833333333333 0.9155\n",
      "0.91045 0.9179\n",
      "0.9136833333333333 0.9181\n",
      "0.9122166666666667 0.9144\n",
      "0.9116 0.9141\n",
      "0.91365 0.9182\n",
      "0.9126666666666666 0.9162\n",
      "0.9134833333333333 0.9159\n",
      "0.9135333333333333 0.917\n",
      "0.90955 0.9144\n",
      "0.9124166666666667 0.9167\n",
      "0.9124 0.9175\n",
      "0.9131 0.9158\n",
      "0.9116666666666666 0.9154\n",
      "0.9120666666666667 0.916\n",
      "0.9136666666666666 0.9175\n",
      "0.9133333333333333 0.9147\n",
      "0.9130166666666667 0.9154\n",
      "0.9133333333333333 0.9145\n",
      "0.91145 0.9138\n",
      "0.9091333333333333 0.9115\n",
      "0.9106666666666666 0.914\n",
      "0.9057333333333333 0.9075\n",
      "0.9099166666666667 0.9112\n",
      "0.91095 0.9125\n",
      "0.91225 0.9159\n",
      "0.9110833333333334 0.9137\n",
      "0.9131 0.9148\n",
      "0.9118166666666667 0.9132\n",
      "0.9114666666666666 0.9122\n",
      "0.91195 0.9133\n",
      "0.90955 0.9133\n",
      "0.9139666666666667 0.9194\n",
      "0.9137833333333333 0.9176\n",
      "0.9139333333333334 0.9182\n",
      "0.9141 0.9185\n",
      "0.91415 0.9192\n",
      "0.9134333333333333 0.9192\n",
      "0.9138833333333334 0.9183\n",
      "0.9122 0.9179\n",
      "0.9138166666666667 0.9174\n",
      "0.91505 0.9178\n",
      "0.9144 0.9173\n",
      "0.9138 0.9174\n",
      "0.9144833333333333 0.9194\n",
      "0.9138166666666667 0.9168\n",
      "0.9136833333333333 0.9171\n",
      "0.9135666666666666 0.9188\n",
      "0.9123 0.9156\n",
      "0.9138 0.9173\n",
      "0.9147833333333333 0.9182\n",
      "0.9140833333333334 0.9192\n",
      "0.91355 0.9181\n",
      "0.91415 0.9174\n",
      "0.9142166666666667 0.9204\n",
      "0.9104833333333333 0.9165\n",
      "0.9154666666666667 0.9195\n",
      "0.9148666666666667 0.9193\n",
      "0.9152333333333333 0.9181\n",
      "0.9153666666666667 0.9173\n",
      "0.9140166666666667 0.9168\n",
      "0.9129666666666667 0.9172\n",
      "0.9135333333333333 0.9172\n",
      "0.9128 0.9155\n",
      "0.9146666666666666 0.9193\n",
      "0.9141833333333333 0.9179\n",
      "0.9147833333333333 0.9212\n",
      "0.913 0.915\n",
      "0.9146166666666666 0.9167\n",
      "0.91515 0.9176\n",
      "0.9146166666666666 0.9195\n",
      "0.9163833333333333 0.9184\n",
      "0.91535 0.9179\n",
      "0.9157 0.9196\n",
      "0.9111666666666667 0.9142\n",
      "0.9098 0.9149\n",
      "0.9143166666666667 0.9197\n",
      "0.9135 0.9179\n",
      "0.9161333333333334 0.9203\n",
      "0.9160166666666667 0.92\n",
      "0.9152333333333333 0.9188\n",
      "0.9162166666666667 0.9195\n",
      "0.9136666666666666 0.9168\n",
      "0.9146833333333333 0.9166\n",
      "0.9129833333333334 0.9165\n",
      "0.91695 0.9216\n",
      "0.9165833333333333 0.9219\n",
      "0.9157166666666666 0.9199\n",
      "0.9166166666666666 0.9211\n",
      "0.91635 0.9219\n",
      "0.9156833333333333 0.92\n",
      "0.91395 0.9154\n",
      "0.9149 0.9154\n",
      "0.9173333333333333 0.9202\n",
      "0.9163333333333333 0.9207\n",
      "0.91555 0.9201\n",
      "0.9145666666666666 0.9186\n",
      "0.9165666666666666 0.92\n",
      "0.91585 0.919\n",
      "0.9155666666666666 0.9191\n",
      "0.9158166666666666 0.9192\n",
      "0.9171833333333334 0.9211\n",
      "0.91665 0.9206\n",
      "0.9165 0.9204\n",
      "0.9162166666666667 0.9193\n",
      "0.91695 0.9197\n",
      "0.9163666666666667 0.9206\n",
      "0.9166166666666666 0.9208\n",
      "0.9166166666666666 0.9199\n",
      "0.9174 0.921\n",
      "0.9158833333333334 0.9193\n",
      "0.9165333333333333 0.9201\n",
      "0.9142833333333333 0.9166\n",
      "0.9167833333333333 0.9194\n",
      "0.9174 0.9205\n",
      "0.9161666666666667 0.9198\n",
      "0.9170333333333334 0.9201\n",
      "0.9175666666666666 0.921\n",
      "0.9179 0.9208\n",
      "0.9176666666666666 0.9225\n",
      "0.9180166666666667 0.9225\n",
      "0.9185166666666666 0.9228\n",
      "0.9186166666666666 0.9234\n",
      "0.9177666666666666 0.9209\n",
      "0.9160666666666667 0.922\n",
      "0.9177 0.9243\n",
      "0.9139666666666667 0.9188\n",
      "0.9153333333333333 0.917\n",
      "0.9124833333333333 0.9138\n",
      "0.9181 0.9222\n",
      "0.9178166666666666 0.9225\n",
      "0.9158166666666666 0.9182\n",
      "0.91785 0.92\n",
      "0.9179666666666667 0.9228\n",
      "0.9182666666666667 0.9222\n",
      "0.91695 0.9224\n",
      "0.9186333333333333 0.9225\n",
      "0.9186 0.9235\n",
      "0.91905 0.9224\n",
      "0.9172 0.9217\n",
      "0.91645 0.9203\n",
      "0.9136 0.9199\n",
      "0.9158 0.9199\n",
      "0.9152166666666667 0.9195\n",
      "0.9182 0.9222\n",
      "0.9180666666666667 0.9223\n",
      "0.9184166666666667 0.9225\n",
      "0.9186166666666666 0.9217\n",
      "0.9156833333333333 0.9186\n",
      "0.9176 0.9213\n",
      "0.9171166666666667 0.9199\n",
      "0.9170833333333334 0.9206\n",
      "0.91215 0.9152\n",
      "0.90965 0.913\n",
      "0.9148833333333334 0.9187\n",
      "0.9137166666666666 0.9175\n",
      "0.9173166666666667 0.9194\n",
      "0.91875 0.9224\n",
      "0.9173833333333333 0.9209\n",
      "0.9167 0.9189\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(784, 50, 10)\n",
    "\n",
    "iters_num = 1000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    grad = network.gradient(x_batch, t_batch) # loss(predict -> softmax with loss) ->  backprop(반대로 gradient 구하기)\n",
    "\n",
    "    for key in (\"W1\", \"b1\", \"W2\", \"b2\"):\n",
    "        network.params[key] -= learning_rate * grad[key] # network.gradient에서 구한 grad를 적용하여 파라미터 갱신하기\n",
    "\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    train_acc = network.accuracy(x_train, t_train)\n",
    "    test_acc = network.accuracy(x_test, t_test)\n",
    "    train_acc_list.append(train_acc)\n",
    "    test_acc_list.append(test_acc)\n",
    "\n",
    "    print(train_acc, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(0, 100, 0.1)\n",
    "y = test_acc_list\n",
    "y2 = train_acc_list\n",
    "y3 = train_loss_list\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.plot(x, y2)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
